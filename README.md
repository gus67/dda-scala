# åˆ†å¸ƒå¼æ•°æ®ä¼ è¾“ç»„ä»¶ DDA

version | update | items 
:--: | :--: | :--:
0.10 | åˆå§‹é¡¹ç›®| 2018.02.28
0.11 | é¡¹ç›®æ•´ä½“æ¡†æ¶å®Œæˆ|2018.03.09
0.12 | ä»£ç æ€§èƒ½ä¼˜åŒ–| 2018.03.13
0.13 | ä»£ç review| 2018.03.21

ğŸ”— [Scala ä¸­æ–‡å®˜æ–¹æ–‡æ¡£](http://docs.scala-lang.org/zh-cn/overviews/)

# ç¯å¢ƒè¯´æ˜

> 1ã€æµ‹è¯•æœåŠ¡å™¨kafka å¯¹åº”çš„åœ°å€
> /up/kafka_2.11-1.0.0/bin/kafka-console-consumer.sh --bootstrap-server 172.18.111.4:9093,172.18.111.5:9093,172.18.111.6:9093 --new-consumer --topic t6
>
> 2ã€æµ‹è¯•æœåŠ¡å™¨Hdfs å¯¹åº”çš„åœ°å€
> hdfs://hadoop ï¼ˆhdfs://192.168.129.186:8020/ï¼‰


# åˆ†å¸ƒå¼ä¼ è¾“ç³»ç»Ÿå¤„ç†æµç¨‹æ¦‚è¦å›¾

![Alt text](https://github.com/gus67/dda-scala/blob/master/src/main/resources/2.png)


# åˆ†å¸ƒå¼ä¼ è¾“ç³»ç»Ÿå¼€å‘æ–‡æ¡£æ¦‚è¦

1ã€åˆå§‹åŒ–é…ç½®æ–‡ä»¶ï¼Œè·å¾—å…³é”®å±æ€§

reg_sinks_map:

K -> æ­£åˆ™è¡¨è¾¾å­—ç¬¦ä¸²

V -> CSåŒ…å«æ’ä»¶éœ€è¦çš„ç±»ï¼Œä»¥åŠç›¸å¯¹åº”è¾“å‡ºçš„SINKï¼ˆKafkaSinkï¼ŒHdfsSinkï¼‰

reg_quene_map:

K -> æ­£åˆ™è¡¨è¾¾å­—ç¬¦ä¸²

V ->  ArrayBlockingQueue[DDAFile]] DDAFile == class DDAFile(val fileName: String, val path: String, val cs: CS)

```scala
//æ­£åˆ™ä¸è¾“å‡ºæºå¯¹åº”è¡¨
var reg_sinks_map: Map[String, CS] = Map()

var reg_quene_map: Map[String, ArrayBlockingQueue[DDAFile]] = Map()
```

2ã€åˆå§‹åŒ–é…ç½®æ–‡ä»¶å®Œæˆä»¥åï¼Œå•ç‹¬ä¸€ä¸ªçº¿ç¨‹ï¼Œé€’å½’æ‰«ææ ¹ç›®å½•ä¸‹ï¼ˆå«ï¼‰æ‰€æœ‰å­æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰éCOMPLETEDåç¼€çš„æ–‡ä»¶

``` scala 
val s = Seq("bash", "-c", s"find ${InitFileSystem.root_path} -type f  ! -name '*.COMPLETED' $timing ") !!
```

3ã€éªŒè¯æ‰«æå‡ºæ¥çš„æ–‡ä»¶æ˜¯å¦ç¬¦åˆæ­£åˆ™è¡¨è¾¾ï¼Œç¬¦åˆæ­£åˆ™è¡¨è¾¾çš„ä¸€å¾‹æ”¾è¿›ç›¸åº”çš„é˜Ÿåˆ—ä¹‹ä¸­

```scala
 loop.breakable {

//ä»»æ„æ–‡ä»¶åªä¼šåŒ¹é…åˆ°ä¸€ä¸ªæ­£åˆ™
  for (x <- regSet) {

    if (new Regex(x) findFirstIn s nonEmpty) {

      InitFileSystem.reg_quene_map(x).put(new DDAFile(InitFileSystem.getFileNameWithSuffix(s), s, InitFileSystem.reg_sinks_map(x)))

      log.info(s"\n\u001b[34;1m$s åŒ¹é…åˆ°ä¸€ä¸ªæ­£åˆ™ $x \u001b[0m\n".replace("),", ""))

      notFound = false

      loop.break
      }
    }
  }
```

4ã€å¹¶è¡Œçš„ä¸€ä¸ªçº¿ç¨‹ï¼Œæ–‡ä»¶å‘ç°çº¿ç¨‹ï¼Œå‘ç°è‡ªè¿›ç¨‹å¯åŠ¨ä»¥åï¼Œå®æ—¶ä¾¦æµ‹æ–‡ä»¶ä¸‹CREATEæ–‡ä»¶æ˜¯ä»¶ï¼Œä¾¦æµ‹åçš„æ–‡ä»¶å¤„ç†é€»è¾‘åŒ3

```scala
 val interval = TimeUnit.SECONDS.toMillis(5)

 val observer = new FileAlterationObserver(InitFileSystem.root_path)

 observer.addListener(new FoundFile())

 //åˆ›å»ºæ–‡ä»¶å˜åŒ–ç›‘å¬å™¨
 val monitor = new FileAlterationMonitor(interval, observer)

 // å¼€å§‹ç›‘æ§
 monitor.start()
```

5ã€å¹¶è¡Œçš„å¤šä¸ªé˜Ÿåˆ—å¤„ç†çº¿ç¨‹ï¼Œæ¯ä¸€ä¸ªé˜Ÿåˆ—å‘ç›®æ ‡Sinkå‘é€æ•°æ®

```scala
for ((_, v) <- InitFileSystem.reg_quene_map) {

      Executors.newSingleThreadExecutor().submit(new Runnable {

      override def run(): Unit = {

        val abq = v

        var fileTmp = ""

        while (true) {

          try {
          
             val dda = abq.take
...
...
... ç•¥

}

/**
  * å®é™…å¤„ç†ç»†èŠ‚
  * 1ã€æ’ä»¶åŒ–åå°„     PluginUtils.reflectPlugin(clazz.split("!!")(0), clazz.split("!!")(1), path, lastFileName)
  * 
  * 2ã€è½¬ç           val res = Seq("bash", "-c", s"file --mime-encoding $lastFileName") !!
  * 
  *                           Seq("bash", "-c", s"iconv -f gbk -t utf-8 $lastFileName -o $tmpPath.UTF-8 ") !!
  *                           
  * 3ã€æ–‡ä»¶å¤´+è¡Œå·   Seq("bash", "-c", "awk '$0=\"" + path + "=\"NR\"\037 \"$0' " + tmpFileArr.last + " > " + s"${tmpFileArr.last}.LINE_NUM") !!
  * 
  */

```

6ã€é˜Ÿåˆ—å†…éƒ¨å¤„ç†é€»è¾‘

```scala
 for (sink <- sinks) {

                sink match {

                  case k: KafkaSink =>

                    new KafkaUtils().kafkaProducer4DDA(k, tmpFileArr)

                  case h: HdfsSink =>

                    new HdfsUtils().hdfsPut4DDA(h, tmpFileArr)

                  case f: FtpSink =>
                   
                     .
                     .
                     .
                  case _ => println("error")
                }
              }
```

7ã€æ‰€æœ‰å¤±è´¥çš„æ–‡ä»¶å‡åœ¨å½“å‰åŒ…ä¸‹.failed,ç”±è¿ç»´å¤„ç†